robot = get_robot(args.robot)(xmlfile)
params = robot.params()

use normed parameters

env is just normal environment (which we can replace with our own environment)
The robot parames are passed in through the xml file (which we can change to make it hardcoded)

Everytime, observation is concatenated with the robot parameters in the augmented environment

Could be the initialization or the assignment problem

right now I set the range to 0.1, 0.1, 0.3
While the sampling is around these values
(0.05 - 0.2) (0.05 - 0.2) (0.15 - 0.6)


It is not using the GPU... So it might be using CPU / stuck at somewhere

1. It is on-policy, meaning that a replay buffer is not being used
2. rollout_length = 1024??? Meaning it will collect 1024 amount of data and then use it to do update?


Also, need a way to save the robot parameters

episode length: need to change in both env and init

change the save freq
change the number of episode


chop means halve, this use the mpi_robot, and currently haven't been tested at all (so we might actually get some bug when dealing with this)

self.timesteps_per_step = self.nenv * self.rollout_length
							8*64 (previously 1024)
							How many actions in total
We have 8 envs in total everytime

8 processes, only number 1 env saves the result

all with rsp to t: initially 1e9

if rollout = 1024*8
	doesn't matter

10*8 (pre) + 8*10*8 (update) + 10*8 (post)
	Looks like something wrong? Cos we really only need 3 chops

	chop set the probability to 0, and the probability is synchronized across the environments, so the number of enviornment has nothing to do with the number of prob distri

512 + 2*512 + 512

chopping takes a long time (but it is probably reasonable)
Why does it chop on round 4 (instead of round 1, 2, 3?)

choping is taking too much time
#experiment: set sampling to 1, see how it goes